+++
title = "Week 2 Update"
date = "2025-09-11T17:42:21-05:00"
author = "Leonora"
authorTwitter = "" #do not include @
cover = ""
coverCaption = ""
tags = ["", ""]
keywords = ["", ""]
description = ""
showFullContent = false
readingTime = false
hideComments = false
color = "" #color from the theme settings
+++

This week I worked on conceptualizing a project idea, setting up my personal website, and researching the current state of causal inference techniques and libraries. My main struggle with finding a project has been balancing my desire to do open-ended research with the need to create a tangible result which demonstrates my skills. In my introduction post I mentioned my interest in causality, and Professor Guinn suggested a project to create a causal inference pipeline with a library such as DoWhy or CausalNex with a public dataset and make it available as an API-based web service.

I like this idea a lot, because it has a good balance of theoretical interest with practicality, as well as a balance of demonstrating/reinforcing skills I have acquired as part of this program with learning new ones. I have created similar models in the Machine Learning class, have used Flask in the Software Development class, etc. but I have not combined the two nor have I done extensive API design. I also like that the minimum viable product seems very attainable, which gives me space to do research on the side and really gain a deep understanding of how the model I create works and experiment with various parameters and techniques. I could also do something like extending the baseline functionality of the API with a natural language interface.

The main challenge I face now is finding a good dataset for the project. In ML I found the majority of publicly available datasets lacking. My interest is in the model architecture itself less than any particular domain, so I will ultimately be looking for something that seems the most likely to contain interesting causal relationships that could be queried. I think I will focus my search on healthcare data first as there is a sizeable medical technology presence in my area and it is a well known application of causal inference and expert system technologies. I may also look into economic data, as the field of econometrics is closely related to ML/causality theory. I am also aware that I do not necessarily have to commit to a single data source at the outset of or for the whole duration of the project, so whatever area I choose I will probably use a smaller dataset or subset while I design the overall pipeline.

Besides looking for potential datasets, this week I need to survey the libraries I will use to implement the model (DoWhy, CausalNex, EconML, scipy/statsmodels, ...?) and web service (Flask/FastAPI, others?). Again I do not think that I have to make a final decision immediately, but rather experiment with all options that seem reasonable and document my findings. From there I should be in a good position to make a decision as my project's subject and goals become more clear. While I know that I work best with a relatively open and flexible approach, I do think that I need to add some structure to my work going forward as compared to this last week. By the end of next week I should also have some general outline of the weekly schedule and deadlines for myself, but allow room for adjustments.